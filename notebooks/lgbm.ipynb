{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "root_path = r'C:\\Users\\ADE17\\Desktop\\Masters\\Projects\\AIChallenge_OWL\\SollIch-Hackathon_Daten\\Data_Participants3'\n",
    "def load_data(root_path, mode='train'):\n",
    "    data_dict = {}\n",
    "    if mode == 'train':\n",
    "        x_folder = \"Train_X\"\n",
    "        y_folder = \"Train_Y\"\n",
    "    else:\n",
    "        x_folder = \"Eval_X\"\n",
    "        y_folder = \"Eval_Y\"\n",
    "    x_files = os.listdir(os.path.join(root_path, x_folder))\n",
    "    y_files = os.listdir(os.path.join(root_path, y_folder))\n",
    "\n",
    "    for x_file, y_file in zip(x_files, y_files):\n",
    "        if x_file.endswith('.pq') and y_file.endswith('.pq'):\n",
    "            path_X = os.path.join(x_folder, x_file)\n",
    "            path_Y = os.path.join(y_folder, y_file)\n",
    "            df_X = pd.read_parquet(os.path.join(root_path, path_X))\n",
    "            df_Y = pd.read_parquet(os.path.join(root_path, path_Y))\n",
    "            target_col_1 = df_X['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage']\n",
    "            targets = pd.concat([df_Y, target_col_1], axis=1)\n",
    "            df_X = df_X.drop(['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage'], axis=1)\n",
    "            date = x_file.split('_')[1:]  # Extracting month and day\n",
    "            date_key = '_'.join(date)[:5]  # Creating the 'MM_DD' format\n",
    "            data_dict[date_key] = {'features': df_X, 'targets': targets}\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "train_data = load_data(root_path)\n",
    "val_data = load_data(root_path, mode='val')\n",
    "def custom_weighted_error(true_values, predicted_values):\n",
    "    absolute_errors = np.abs(true_values - predicted_values)\n",
    "    \n",
    "    points = 0\n",
    "    for error in absolute_errors:\n",
    "        if error <= 0.05:\n",
    "            points += 1\n",
    "        elif 0.05 < error <= 0.1:\n",
    "            points += 0.5\n",
    "        elif 0.1 < error <= 0.5:\n",
    "            points += 0.25\n",
    "        else:\n",
    "            points += 0\n",
    "    \n",
    "    return points \n",
    "\n",
    "def custom_weighted_error_xgb(preds, dtrain):\n",
    "    true_values = dtrain.get_label()\n",
    "    \n",
    "    absolute_errors = np.abs(true_values - preds)\n",
    "    \n",
    "    points = 0\n",
    "    for error in absolute_errors:\n",
    "        if error <= 0.05:\n",
    "            points += 1\n",
    "        elif 0.05 < error <= 0.1:\n",
    "            points += 0.5\n",
    "        elif 0.1 < error <= 0.5:\n",
    "            points += 0.25\n",
    "        else:\n",
    "            points += 0\n",
    "    \n",
    "    return 'custom_weighted_error', points / len(preds) * 100\n",
    "\n",
    "def custom_error_duration(preds, dtrain):\n",
    "    true_values = dtrain.get_label()\n",
    "    \n",
    "    preds_array = preds.astype(float)\n",
    "    \n",
    "    absolute_errors = np.abs(true_values - preds_array)\n",
    "    \n",
    "    error_less_than_01 = np.sum(absolute_errors < 0.1) / len(absolute_errors)\n",
    "    \n",
    "    error_intervals = []\n",
    "    current_interval = 0\n",
    "    for error in absolute_errors:\n",
    "        if error > 0.1:\n",
    "            current_interval += 1\n",
    "        else:\n",
    "            if current_interval > 0:\n",
    "                error_intervals.append(current_interval)\n",
    "                current_interval = 0\n",
    "    \n",
    "    max_intervals_1 = len(absolute_errors) / 2\n",
    "    max_intervals_2 = len(absolute_errors) / 8\n",
    "    \n",
    "    points = 0\n",
    "    for interval in error_intervals:\n",
    "        if interval <= 1:\n",
    "            points += max(0, 0.5 - (interval / max_intervals_1))\n",
    "        elif 2 <= interval <= 10:\n",
    "            points += max(0, 0.25 - (interval / max_intervals_2))\n",
    "    \n",
    "    # Calculate the error duration metric\n",
    "    error_duration_points = (1 - error_less_than_01) * 100 + points\n",
    "    \n",
    "    return 'custom_error_duration', error_duration_points \n",
    "def add_time_columns(df):\n",
    "    df['Hour'] = df.index.hour\n",
    "    df['Minute'] = df.index.minute\n",
    "    df['Second'] = df.index.second\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_features_1 = add_time_columns(train_data['03_14']['features'])\n",
    "sample_train_targets_1 = train_data['03_14']['targets']\n",
    "sample_train_features_2 = add_time_columns(train_data['03_15']['features'])\n",
    "sample_train_targets_2 = train_data['03_15']['targets']\n",
    "\n",
    "final_train_feat = pd.concat([sample_train_features_1, sample_train_features_2], axis=0)\n",
    "final_train_targets = pd.concat([sample_train_targets_1, sample_train_targets_2], axis=0)\n",
    "final_train_targets_1 = final_train_targets['ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage']\n",
    "final_train_targets_2 = final_train_targets['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage']\n",
    "\n",
    "sample_val_features = add_time_columns(val_data['03_16']['features'])\n",
    "sample_val_targets = val_data['03_16']['targets']\n",
    "sample_val_targets_1 = val_data['03_16']['targets']['ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage']\n",
    "sample_val_targets_2 = val_data['03_16']['targets']['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:24.86623\teval-mae:24.79254\n",
      "[1]\ttrain-mae:17.40678\teval-mae:17.35576\n",
      "[2]\ttrain-mae:12.18512\teval-mae:12.14595\n",
      "[3]\ttrain-mae:8.52982\teval-mae:8.50094\n",
      "[4]\ttrain-mae:5.97109\teval-mae:5.94706\n",
      "[5]\ttrain-mae:4.17994\teval-mae:4.16069\n",
      "[6]\ttrain-mae:2.92610\teval-mae:2.91042\n",
      "[7]\ttrain-mae:2.04840\teval-mae:2.03517\n",
      "[8]\ttrain-mae:1.43397\teval-mae:1.42234\n",
      "[9]\ttrain-mae:1.00389\teval-mae:0.99459\n",
      "[10]\ttrain-mae:0.70280\teval-mae:0.69457\n",
      "[11]\ttrain-mae:0.49202\teval-mae:0.48528\n",
      "[12]\ttrain-mae:0.34454\teval-mae:0.33967\n",
      "[13]\ttrain-mae:0.24138\teval-mae:0.23826\n",
      "[14]\ttrain-mae:0.16930\teval-mae:0.16709\n",
      "[15]\ttrain-mae:0.11911\teval-mae:0.11785\n",
      "[16]\ttrain-mae:0.08458\teval-mae:0.08395\n",
      "[17]\ttrain-mae:0.06113\teval-mae:0.06064\n",
      "[18]\ttrain-mae:0.04525\teval-mae:0.04492\n",
      "[19]\ttrain-mae:0.03480\teval-mae:0.03428\n",
      "[20]\ttrain-mae:0.02824\teval-mae:0.02755\n",
      "[21]\ttrain-mae:0.02360\teval-mae:0.02334\n",
      "[22]\ttrain-mae:0.02071\teval-mae:0.02061\n",
      "[23]\ttrain-mae:0.01863\teval-mae:0.01861\n",
      "[24]\ttrain-mae:0.01720\teval-mae:0.01749\n",
      "[25]\ttrain-mae:0.01620\teval-mae:0.01705\n",
      "[26]\ttrain-mae:0.01561\teval-mae:0.01662\n",
      "[27]\ttrain-mae:0.01514\teval-mae:0.01631\n",
      "[28]\ttrain-mae:0.01473\teval-mae:0.01596\n",
      "[29]\ttrain-mae:0.01446\teval-mae:0.01587\n",
      "[30]\ttrain-mae:0.01414\teval-mae:0.01594\n",
      "[31]\ttrain-mae:0.01393\teval-mae:0.01572\n",
      "[32]\ttrain-mae:0.01382\teval-mae:0.01566\n",
      "[33]\ttrain-mae:0.01354\teval-mae:0.01558\n",
      "[34]\ttrain-mae:0.01345\teval-mae:0.01552\n",
      "[35]\ttrain-mae:0.01337\teval-mae:0.01548\n",
      "[36]\ttrain-mae:0.01316\teval-mae:0.01550\n",
      "[37]\ttrain-mae:0.01313\teval-mae:0.01550\n",
      "[38]\ttrain-mae:0.01293\teval-mae:0.01534\n",
      "[39]\ttrain-mae:0.01285\teval-mae:0.01536\n",
      "[40]\ttrain-mae:0.01282\teval-mae:0.01535\n",
      "[41]\ttrain-mae:0.01277\teval-mae:0.01535\n",
      "[42]\ttrain-mae:0.01275\teval-mae:0.01534\n",
      "[43]\ttrain-mae:0.01268\teval-mae:0.01523\n",
      "[44]\ttrain-mae:0.01262\teval-mae:0.01525\n",
      "[45]\ttrain-mae:0.01256\teval-mae:0.01520\n",
      "[46]\ttrain-mae:0.01242\teval-mae:0.01517\n",
      "[47]\ttrain-mae:0.01241\teval-mae:0.01520\n",
      "[48]\ttrain-mae:0.01236\teval-mae:0.01523\n",
      "[49]\ttrain-mae:0.01232\teval-mae:0.01522\n",
      "[50]\ttrain-mae:0.01229\teval-mae:0.01519\n",
      "[51]\ttrain-mae:0.01225\teval-mae:0.01520\n",
      "[52]\ttrain-mae:0.01214\teval-mae:0.01521\n",
      "[53]\ttrain-mae:0.01209\teval-mae:0.01514\n",
      "[54]\ttrain-mae:0.01199\teval-mae:0.01512\n",
      "[55]\ttrain-mae:0.01191\teval-mae:0.01515\n",
      "[56]\ttrain-mae:0.01188\teval-mae:0.01514\n",
      "[57]\ttrain-mae:0.01181\teval-mae:0.01514\n",
      "[58]\ttrain-mae:0.01178\teval-mae:0.01514\n",
      "[59]\ttrain-mae:0.01170\teval-mae:0.01509\n",
      "[60]\ttrain-mae:0.01167\teval-mae:0.01509\n",
      "[61]\ttrain-mae:0.01164\teval-mae:0.01511\n",
      "[62]\ttrain-mae:0.01161\teval-mae:0.01510\n",
      "[63]\ttrain-mae:0.01151\teval-mae:0.01513\n",
      "[64]\ttrain-mae:0.01148\teval-mae:0.01513\n",
      "[65]\ttrain-mae:0.01143\teval-mae:0.01512\n",
      "[66]\ttrain-mae:0.01141\teval-mae:0.01511\n",
      "[67]\ttrain-mae:0.01139\teval-mae:0.01511\n",
      "[68]\ttrain-mae:0.01135\teval-mae:0.01511\n",
      "[69]\ttrain-mae:0.01122\teval-mae:0.01510\n",
      "[70]\ttrain-mae:0.01113\teval-mae:0.01512\n",
      "[71]\ttrain-mae:0.01105\teval-mae:0.01509\n",
      "[72]\ttrain-mae:0.01104\teval-mae:0.01510\n",
      "[73]\ttrain-mae:0.01100\teval-mae:0.01510\n",
      "[74]\ttrain-mae:0.01090\teval-mae:0.01510\n",
      "[75]\ttrain-mae:0.01087\teval-mae:0.01511\n",
      "[76]\ttrain-mae:0.01081\teval-mae:0.01508\n",
      "[77]\ttrain-mae:0.01081\teval-mae:0.01508\n",
      "[78]\ttrain-mae:0.01077\teval-mae:0.01513\n",
      "[79]\ttrain-mae:0.01073\teval-mae:0.01512\n",
      "[80]\ttrain-mae:0.01071\teval-mae:0.01512\n",
      "[81]\ttrain-mae:0.01069\teval-mae:0.01511\n",
      "[82]\ttrain-mae:0.01060\teval-mae:0.01511\n",
      "[83]\ttrain-mae:0.01053\teval-mae:0.01515\n",
      "[84]\ttrain-mae:0.01045\teval-mae:0.01517\n",
      "[85]\ttrain-mae:0.01042\teval-mae:0.01517\n",
      "[86]\ttrain-mae:0.01039\teval-mae:0.01518\n",
      "[87]\ttrain-mae:0.01038\teval-mae:0.01518\n",
      "[88]\ttrain-mae:0.01036\teval-mae:0.01512\n",
      "[89]\ttrain-mae:0.01034\teval-mae:0.01512\n",
      "[90]\ttrain-mae:0.01030\teval-mae:0.01522\n",
      "[91]\ttrain-mae:0.01024\teval-mae:0.01523\n",
      "[92]\ttrain-mae:0.01022\teval-mae:0.01522\n",
      "[93]\ttrain-mae:0.01019\teval-mae:0.01522\n",
      "[94]\ttrain-mae:0.01015\teval-mae:0.01521\n",
      "[95]\ttrain-mae:0.01010\teval-mae:0.01523\n",
      "[96]\ttrain-mae:0.01005\teval-mae:0.01525\n",
      "[97]\ttrain-mae:0.01000\teval-mae:0.01523\n",
      "[98]\ttrain-mae:0.00996\teval-mae:0.01524\n",
      "[99]\ttrain-mae:0.00993\teval-mae:0.01522\n",
      "[100]\ttrain-mae:0.00991\teval-mae:0.01522\n",
      "[101]\ttrain-mae:0.00990\teval-mae:0.01522\n",
      "[102]\ttrain-mae:0.00988\teval-mae:0.01521\n",
      "[103]\ttrain-mae:0.00985\teval-mae:0.01523\n",
      "[104]\ttrain-mae:0.00984\teval-mae:0.01522\n",
      "[105]\ttrain-mae:0.00980\teval-mae:0.01524\n",
      "[106]\ttrain-mae:0.00978\teval-mae:0.01524\n",
      "[107]\ttrain-mae:0.00976\teval-mae:0.01524\n",
      "[108]\ttrain-mae:0.00972\teval-mae:0.01518\n",
      "[109]\ttrain-mae:0.00969\teval-mae:0.01522\n",
      "[110]\ttrain-mae:0.00967\teval-mae:0.01522\n",
      "[111]\ttrain-mae:0.00964\teval-mae:0.01523\n",
      "[112]\ttrain-mae:0.00964\teval-mae:0.01523\n",
      "[113]\ttrain-mae:0.00959\teval-mae:0.01526\n",
      "[114]\ttrain-mae:0.00955\teval-mae:0.01523\n",
      "[115]\ttrain-mae:0.00947\teval-mae:0.01523\n",
      "[116]\ttrain-mae:0.00943\teval-mae:0.01521\n",
      "[117]\ttrain-mae:0.00941\teval-mae:0.01522\n",
      "[118]\ttrain-mae:0.00936\teval-mae:0.01525\n",
      "[119]\ttrain-mae:0.00934\teval-mae:0.01526\n",
      "[120]\ttrain-mae:0.00933\teval-mae:0.01526\n",
      "[121]\ttrain-mae:0.00932\teval-mae:0.01526\n",
      "[122]\ttrain-mae:0.00930\teval-mae:0.01526\n",
      "[123]\ttrain-mae:0.00926\teval-mae:0.01523\n",
      "[124]\ttrain-mae:0.00925\teval-mae:0.01523\n",
      "[125]\ttrain-mae:0.00924\teval-mae:0.01522\n",
      "[126]\ttrain-mae:0.00923\teval-mae:0.01522\n",
      "[127]\ttrain-mae:0.00922\teval-mae:0.01522\n",
      "[128]\ttrain-mae:0.00920\teval-mae:0.01523\n",
      "[129]\ttrain-mae:0.00919\teval-mae:0.01523\n",
      "[130]\ttrain-mae:0.00918\teval-mae:0.01523\n",
      "[131]\ttrain-mae:0.00917\teval-mae:0.01523\n",
      "[132]\ttrain-mae:0.00915\teval-mae:0.01525\n",
      "[133]\ttrain-mae:0.00914\teval-mae:0.01525\n",
      "[134]\ttrain-mae:0.00912\teval-mae:0.01531\n",
      "[135]\ttrain-mae:0.00912\teval-mae:0.01525\n",
      "[136]\ttrain-mae:0.00910\teval-mae:0.01524\n",
      "[137]\ttrain-mae:0.00911\teval-mae:0.01527\n",
      "[138]\ttrain-mae:0.00908\teval-mae:0.01527\n",
      "[139]\ttrain-mae:0.00907\teval-mae:0.01527\n",
      "[140]\ttrain-mae:0.00901\teval-mae:0.01527\n",
      "[141]\ttrain-mae:0.00898\teval-mae:0.01527\n",
      "[142]\ttrain-mae:0.00897\teval-mae:0.01528\n",
      "[143]\ttrain-mae:0.00895\teval-mae:0.01530\n",
      "[144]\ttrain-mae:0.00892\teval-mae:0.01530\n",
      "[145]\ttrain-mae:0.00886\teval-mae:0.01532\n",
      "[146]\ttrain-mae:0.00883\teval-mae:0.01531\n",
      "[147]\ttrain-mae:0.00881\teval-mae:0.01529\n",
      "[148]\ttrain-mae:0.00880\teval-mae:0.01528\n",
      "[149]\ttrain-mae:0.00874\teval-mae:0.01528\n",
      "[150]\ttrain-mae:0.00873\teval-mae:0.01529\n",
      "[151]\ttrain-mae:0.00872\teval-mae:0.01528\n",
      "[152]\ttrain-mae:0.00869\teval-mae:0.01530\n",
      "[153]\ttrain-mae:0.00867\teval-mae:0.01532\n",
      "[154]\ttrain-mae:0.00866\teval-mae:0.01532\n",
      "[155]\ttrain-mae:0.00860\teval-mae:0.01532\n",
      "[156]\ttrain-mae:0.00858\teval-mae:0.01536\n",
      "[157]\ttrain-mae:0.00857\teval-mae:0.01537\n",
      "[158]\ttrain-mae:0.00856\teval-mae:0.01538\n",
      "[159]\ttrain-mae:0.00852\teval-mae:0.01539\n",
      "[160]\ttrain-mae:0.00850\teval-mae:0.01538\n",
      "[161]\ttrain-mae:0.00849\teval-mae:0.01539\n",
      "[162]\ttrain-mae:0.00845\teval-mae:0.01540\n",
      "[163]\ttrain-mae:0.00844\teval-mae:0.01537\n",
      "[164]\ttrain-mae:0.00842\teval-mae:0.01538\n",
      "[165]\ttrain-mae:0.00841\teval-mae:0.01536\n",
      "[166]\ttrain-mae:0.00840\teval-mae:0.01537\n",
      "[167]\ttrain-mae:0.00840\teval-mae:0.01537\n",
      "[168]\ttrain-mae:0.00838\teval-mae:0.01537\n",
      "[169]\ttrain-mae:0.00838\teval-mae:0.01537\n",
      "[170]\ttrain-mae:0.00838\teval-mae:0.01538\n",
      "[171]\ttrain-mae:0.00837\teval-mae:0.01538\n",
      "[172]\ttrain-mae:0.00835\teval-mae:0.01539\n",
      "[173]\ttrain-mae:0.00834\teval-mae:0.01538\n",
      "[174]\ttrain-mae:0.00833\teval-mae:0.01538\n",
      "[175]\ttrain-mae:0.00832\teval-mae:0.01538\n",
      "[176]\ttrain-mae:0.00829\teval-mae:0.01540\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#     'objective': 'reg:squarederror',\n",
    "#     'eta': 0.075,\n",
    "#     'max_depth': 6,\n",
    "#     'min_child_weight': 1,\n",
    "#     'subsample': 1.0,\n",
    "#     'colsample_bytree': 1.0,\n",
    "#     'eval_metric': 'mae',\n",
    "#     'seed': 5\n",
    "# }\n",
    "params = {'eval_metric': 'mae'}\n",
    "\n",
    "# Convert data into DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(final_train_feat, label=final_train_targets_1)\n",
    "dvalid = xgb.DMatrix(sample_val_features, label=sample_val_targets_1)\n",
    "\n",
    "# Training the model\n",
    "num_round = 1000\n",
    "early_stopping_rounds = 100\n",
    "max_time_for_learner = 360  # in seconds\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_boost_round=num_round, evals=watchlist,\n",
    "                  early_stopping_rounds=early_stopping_rounds,\n",
    "                  feval=custom_weighted_error_xgb\n",
    "                  maximize=False, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.21863715442757\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(xgb.DMatrix(sample_val_features))\n",
    "print(custom_weighted_error(sample_val_targets_1, preds)/len(preds) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.55525504013099\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(xgb.DMatrix(sample_val_features))\n",
    "print(custom_weighted_error(sample_val_targets_1, preds)/len(preds) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27ad3057f70>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
