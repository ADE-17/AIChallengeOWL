{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported auto_timeseries version:0.0.81. Call by using:\n",
      "model = auto_timeseries(score_type='rmse',\n",
      "        time_interval='M', non_seasonal_pdq=None, seasonality=False,\n",
      "        seasonal_period=12, model_type=['best'], verbose=2, dask_xgboost_flag=0)\n",
      "model.fit(traindata, ts_column,target)\n",
      "model.predict(testdata, model='best')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from autots import AutoTS\n",
    "from auto_ts import auto_timeseries\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r'C:\\Users\\ADE17\\Desktop\\Masters\\Projects\\AIChallenge_OWL\\SollIch-Hackathon_Daten\\Data_Participants3'\n",
    "def load_data(root_path, mode='train'):\n",
    "    data_dict = {}\n",
    "    if mode == 'train':\n",
    "        x_folder = \"Train_X\"\n",
    "        y_folder = \"Train_Y\"\n",
    "    else:\n",
    "        x_folder = \"Eval_X\"\n",
    "        y_folder = \"Eval_Y\"\n",
    "    x_files = os.listdir(os.path.join(root_path, x_folder))\n",
    "    y_files = os.listdir(os.path.join(root_path, y_folder))\n",
    "\n",
    "    for x_file, y_file in zip(x_files, y_files):\n",
    "        if x_file.endswith('.pq') and y_file.endswith('.pq'):\n",
    "            path_X = os.path.join(x_folder, x_file)\n",
    "            path_Y = os.path.join(y_folder, y_file)\n",
    "            df_X = pd.read_parquet(os.path.join(root_path, path_X))\n",
    "            df_Y = pd.read_parquet(os.path.join(root_path, path_Y))\n",
    "            # target_col_1 = df_X['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage']\n",
    "            targets = df_Y\n",
    "            # df_X = df_X.drop(['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage'], axis=1)\n",
    "            date = x_file.split('_')[1:]  # Extracting month and day\n",
    "            date_key = '_'.join(date)[:5]  # Creating the 'MM_DD' format\n",
    "            data_dict[date_key] = {'features': df_X, 'targets': targets}\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "train_data = load_data(root_path)\n",
    "val_data = load_data(root_path, mode='val')\n",
    "def custom_weighted_error(true_values, predicted_values):\n",
    "    absolute_errors = np.abs(true_values - predicted_values)\n",
    "    \n",
    "    points = 0\n",
    "    for error in absolute_errors:\n",
    "        if error <= 0.05:\n",
    "            points += 1\n",
    "        elif 0.05 < error <= 0.1:\n",
    "            points += 0.5\n",
    "        elif 0.1 < error <= 0.5:\n",
    "            points += 0.25\n",
    "        else:\n",
    "            points += 0\n",
    "    \n",
    "    return points \n",
    "\n",
    "def custom_weighted_error_xgb(preds, dtrain):\n",
    "    true_values = dtrain.get_label()\n",
    "    \n",
    "    absolute_errors = np.abs(true_values - preds)\n",
    "    \n",
    "    points = 0\n",
    "    for error in absolute_errors:\n",
    "        if error <= 0.05:\n",
    "            points += 1\n",
    "        elif 0.05 < error <= 0.1:\n",
    "            points += 0.5\n",
    "        elif 0.1 < error <= 0.5:\n",
    "            points += 0.25\n",
    "        else:\n",
    "            points += 0\n",
    "    \n",
    "    return 'custom_weighted_error', points / len(preds) * 100\n",
    "\n",
    "def custom_error_duration(preds, dtrain):\n",
    "    true_values = dtrain.get_label()\n",
    "    \n",
    "    preds_array = preds.astype(float)\n",
    "    \n",
    "    absolute_errors = np.abs(true_values - preds_array)\n",
    "    \n",
    "    error_less_than_01 = np.sum(absolute_errors < 0.1) / len(absolute_errors)\n",
    "    \n",
    "    error_intervals = []\n",
    "    current_interval = 0\n",
    "    for error in absolute_errors:\n",
    "        if error > 0.1:\n",
    "            current_interval += 1\n",
    "        else:\n",
    "            if current_interval > 0:\n",
    "                error_intervals.append(current_interval)\n",
    "                current_interval = 0\n",
    "    \n",
    "    max_intervals_1 = len(absolute_errors) / 2\n",
    "    max_intervals_2 = len(absolute_errors) / 8\n",
    "    \n",
    "    points = 0\n",
    "    for interval in error_intervals:\n",
    "        if interval <= 1:\n",
    "            points += max(0, 0.5 - (interval / max_intervals_1))\n",
    "        elif 2 <= interval <= 10:\n",
    "            points += max(0, 0.25 - (interval / max_intervals_2))\n",
    "    \n",
    "    # Calculate the error duration metric\n",
    "    error_duration_points = (1 - error_less_than_01) * 100 + points\n",
    "    \n",
    "    return 'custom_error_duration', error_duration_points \n",
    "def add_time_columns(df):\n",
    "    df['Hour'] = df.index.hour\n",
    "    df['Minute'] = df.index.minute\n",
    "    df['Second'] = df.index.second\n",
    "    return df\n",
    "def create_time_series_windows(data, window_size):\n",
    "    windows_X = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        window = data.iloc[i:i + window_size]\n",
    "\n",
    "        windows_X.append(window.values.flatten())\n",
    "\n",
    "    return np.array(windows_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_features_1 = add_time_columns(train_data['03_14']['features'])\n",
    "sample_train_targets_1 = train_data['03_14']['targets']\n",
    "sample_train_features_2 = add_time_columns(train_data['03_15']['features'])\n",
    "sample_train_targets_2 = train_data['03_15']['targets']\n",
    "\n",
    "final_train_feat = pd.concat([sample_train_features_1, sample_train_features_2], axis=0)\n",
    "final_train_targets = pd.concat([sample_train_targets_1, sample_train_targets_2], axis=0)\n",
    "\n",
    "sample_val_features = add_time_columns(val_data['03_16']['features'])\n",
    "sample_val_targets = val_data['03_16']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_timeseries(score_type = 'mae', time_interval='S', seasonality=True, seasonal_period=2,\n",
    "                        model_type = ['ARIMA', 'VAR', 'ML'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of Fit.....\n",
      "    Target variable given as =                            ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage\n",
      "2023-03-14 01:00:00+00:00                                               41.5      \n",
      "2023-03-14 01:00:01+00:00                                               41.5      \n",
      "2023-03-14 01:00:02+00:00                                               41.5      \n",
      "2023-03-14 01:00:03+00:00                                               41.5      \n",
      "2023-03-14 01:00:04+00:00                                               41.5      \n",
      "...                                                                      ...      \n",
      "2023-03-14 01:01:35+00:00                                               41.5      \n",
      "2023-03-14 01:01:36+00:00                                               41.5      \n",
      "2023-03-14 01:01:37+00:00                                               41.5      \n",
      "2023-03-14 01:01:38+00:00                                               41.5      \n",
      "2023-03-14 01:01:39+00:00                                               41.5      \n",
      "\n",
      "[100 rows x 1 columns]\n",
      "Start of loading of data.....\n",
      "    Inputs: ts_column = datetime, sep = ,, target = [                           ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage\n",
      "2023-03-14 01:00:00+00:00                                               41.5      \n",
      "2023-03-14 01:00:01+00:00                                               41.5      \n",
      "2023-03-14 01:00:02+00:00                                               41.5      \n",
      "2023-03-14 01:00:03+00:00                                               41.5      \n",
      "2023-03-14 01:00:04+00:00                                               41.5      \n",
      "...                                                                      ...      \n",
      "2023-03-14 01:01:35+00:00                                               41.5      \n",
      "2023-03-14 01:01:36+00:00                                               41.5      \n",
      "2023-03-14 01:01:37+00:00                                               41.5      \n",
      "2023-03-14 01:01:38+00:00                                               41.5      \n",
      "2023-03-14 01:01:39+00:00                                               41.5      \n",
      "\n",
      "[100 rows x 1 columns]]\n",
      "    Using given input: pandas dataframe...\n",
      "    datetime column exists in given train data...\n",
      "    train data shape = (100, 17)\n",
      "Alert: Could not detect strf_time_format of datetime. Provide strf_time format during \"setup\" for better results.\n",
      "\n",
      "Running Augmented Dickey-Fuller test with paramters:\n",
      "    maxlag: 31 regression: c autolag: BIC\n",
      "Alert! Data is not stationary even after two differencing. Continuing...\n",
      "There is no differencing needed in this datasets for VAR model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25404\\3553530292.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfinal_train_feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_train_feat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m model.fit(\n\u001b[0;32m      4\u001b[0m     \u001b[0mtraindata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_train_feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mts_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'datetime'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADE17\\anaconda3\\anaconda2\\lib\\site-packages\\auto_ts\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, traindata, ts_column, target, sep, cv)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[1;31m### If there is only one column, you assume that to be the target column ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__any_contained_in_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhat_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'var'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Var'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'VAR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stats'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'best'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADE17\\anaconda3\\anaconda2\\lib\\site-packages\\auto_ts\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m     def fit(\n\u001b[0m\u001b[0;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mtraindata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0mts_column\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "final_train_feat['datetime'] = pd.to_datetime(final_train_feat.index)\n",
    "model.fit(\n",
    "    traindata = final_train_feat[:100],\n",
    "    ts_column = 'datetime',\n",
    "    target = final_train_targets[:100]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
