{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "root_path = r'C:\\Users\\ADE17\\Desktop\\Masters\\Projects\\AIChallenge_OWL\\SollIch-Hackathon_Daten\\Data_Participants3'\n",
    "def load_data(root_path, mode='train'):\n",
    "    data_dict = {}\n",
    "    if mode == 'train':\n",
    "        x_folder = \"Train_X\"\n",
    "        y_folder = \"Train_Y\"\n",
    "    else:\n",
    "        x_folder = \"Eval_X\"\n",
    "        y_folder = \"Eval_Y\"\n",
    "    x_files = os.listdir(os.path.join(root_path, x_folder))\n",
    "    y_files = os.listdir(os.path.join(root_path, y_folder))\n",
    "\n",
    "    for x_file, y_file in zip(x_files, y_files):\n",
    "        if x_file.endswith('.pq') and y_file.endswith('.pq'):\n",
    "            path_X = os.path.join(x_folder, x_file)\n",
    "            path_Y = os.path.join(y_folder, y_file)\n",
    "            df_X = pd.read_parquet(os.path.join(root_path, path_X))\n",
    "            df_Y = pd.read_parquet(os.path.join(root_path, path_Y))\n",
    "            # target_col_1 = df_X['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage']\n",
    "            targets = df_Y\n",
    "            df_X = df_X.drop(['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage'], axis=1)\n",
    "            date = x_file.split('_')[1:]  # Extracting month and day\n",
    "            date_key = '_'.join(date)[:5]  # Creating the 'MM_DD' format\n",
    "            data_dict[date_key] = {'features': df_X, 'targets': targets}\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "train_data = load_data(root_path)\n",
    "val_data = load_data(root_path, mode='val')\n",
    "def custom_weighted_error(true_values, predicted_values):\n",
    "    absolute_errors = np.abs(true_values - predicted_values)\n",
    "    \n",
    "    points = 0\n",
    "    for error in absolute_errors:\n",
    "        if error <= 0.05:\n",
    "            points += 1\n",
    "        elif 0.05 < error <= 0.1:\n",
    "            points += 0.5\n",
    "        elif 0.1 < error <= 0.5:\n",
    "            points += 0.25\n",
    "        else:\n",
    "            points += 0\n",
    "    \n",
    "    return points \n",
    "\n",
    "def custom_weighted_error_xgb(preds, dtrain):\n",
    "    true_values = dtrain.get_label()\n",
    "    \n",
    "    absolute_errors = np.abs(true_values - preds)\n",
    "    \n",
    "    points = 0\n",
    "    for error in absolute_errors:\n",
    "        if error <= 0.05:\n",
    "            points += 1\n",
    "        elif 0.05 < error <= 0.1:\n",
    "            points += 0.5\n",
    "        elif 0.1 < error <= 0.5:\n",
    "            points += 0.25\n",
    "        else:\n",
    "            points += 0\n",
    "    \n",
    "    return 'custom_weighted_error', points / len(preds) * 100\n",
    "\n",
    "def custom_error_duration(preds, dtrain):\n",
    "    true_values = dtrain.get_label()\n",
    "    \n",
    "    preds_array = preds.astype(float)\n",
    "    \n",
    "    absolute_errors = np.abs(true_values - preds_array)\n",
    "    \n",
    "    error_less_than_01 = np.sum(absolute_errors < 0.1) / len(absolute_errors)\n",
    "    \n",
    "    error_intervals = []\n",
    "    current_interval = 0\n",
    "    for error in absolute_errors:\n",
    "        if error > 0.1:\n",
    "            current_interval += 1\n",
    "        else:\n",
    "            if current_interval > 0:\n",
    "                error_intervals.append(current_interval)\n",
    "                current_interval = 0\n",
    "    \n",
    "    max_intervals_1 = len(absolute_errors) / 2\n",
    "    max_intervals_2 = len(absolute_errors) / 8\n",
    "    \n",
    "    points = 0\n",
    "    for interval in error_intervals:\n",
    "        if interval <= 1:\n",
    "            points += max(0, 0.5 - (interval / max_intervals_1))\n",
    "        elif 2 <= interval <= 10:\n",
    "            points += max(0, 0.25 - (interval / max_intervals_2))\n",
    "    \n",
    "    # Calculate the error duration metric\n",
    "    error_duration_points = (1 - error_less_than_01) * 100 + points\n",
    "    \n",
    "    return 'custom_error_duration', error_duration_points \n",
    "def add_time_columns(df):\n",
    "    df['Hour'] = df.index.hour\n",
    "    df['Minute'] = df.index.minute\n",
    "    df['Second'] = df.index.second\n",
    "    return df\n",
    "def calculate_points(estimated_values):\n",
    "    thresholds = [(0, 1), (2, 10)]\n",
    "    point_values = [0.5, 0.25]\n",
    "    num_estimates = len(estimated_values)\n",
    "    values_below_threshold = sum(1 for value in estimated_values if abs(value) <= 0.1)\n",
    "    thresh_arr = [1 if abs(i)>0.1 else 0 for i in estimated_values]\n",
    "    #print(thresh_arr)\n",
    "    err_points = 0  # sum for abserr > 0.1\n",
    "    count = 0\n",
    "    for i in thresh_arr:\n",
    "        if i == 1:\n",
    "            count = count +1\n",
    "        else:\n",
    "            if count == 1:\n",
    "                err_points = err_points + 0.5\n",
    "            elif count <= 10 and count >=2:\n",
    "                err_points = err_points + (0.25 * count)\n",
    "            count = 0\n",
    "    if count == 1:\n",
    "        err_points = err_points + 0.5\n",
    "    elif count <= 10 and count >=2:\n",
    "        err_points = err_points + (0.25 * count)\n",
    "    #print (err_points)\n",
    "    return (values_below_threshold + err_points) * 100 /  num_estimates\n",
    "def calculate_points(estimated_values):\n",
    "    num_estimates = len(estimated_values)\n",
    "    values_below_threshold = sum(1 for value in estimated_values if abs(value) <= 0.1)\n",
    "    thresh_arr = [1 if abs(i)>0.1 else 0 for i in estimated_values]\n",
    "    #print(thresh_arr)\n",
    "    err_points = 0  # sum for abserr > 0.1\n",
    "    count = 0\n",
    "    for i in thresh_arr:\n",
    "        if i == 1:\n",
    "            count = count +1\n",
    "        else:\n",
    "            if count == 1:\n",
    "                err_points = err_points + 0.5\n",
    "            elif count <= 10 and count >=2:\n",
    "                err_points = err_points + (0.25 * count)\n",
    "            count = 0\n",
    "    if count == 1:\n",
    "        err_points = err_points + 0.5\n",
    "    elif count <= 10 and count >=2:\n",
    "        err_points = err_points + (0.25 * count)\n",
    "    #print (err_points)\n",
    "    return (values_below_threshold + err_points) * 100 /  num_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notime_sample_train_targets_1 = train_data['03_21']['features']\n",
    "sample_train_features_1 = add_time_columns(train_data['03_21']['features'])\n",
    "sample_train_targets_1 = train_data['03_21']['targets']\n",
    "\n",
    "no_time_sample_train_targets_2 = train_data['03_22']['features']\n",
    "sample_train_features_2 = add_time_columns(train_data['03_22']['features'])\n",
    "sample_train_targets_2 = train_data['03_22']['targets']\n",
    "\n",
    "notime_final_train_feat = pd.concat([notime_sample_train_targets_1, no_time_sample_train_targets_2], axis=0)\n",
    "final_train_feat = pd.concat([sample_train_features_1, sample_train_features_2], axis=0)\n",
    "final_train_targets = pd.concat([sample_train_targets_1, sample_train_targets_2], axis=0)\n",
    "final_train_targets = final_train_targets['ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage']\n",
    "\n",
    "notime_sample_val_features = val_data['03_23']['features']\n",
    "sample_val_features = add_time_columns(val_data['03_23']['features'])\n",
    "# sample_val_targets = val_data['03_16']['targets']\n",
    "sample_val_targets = val_data['03_23']['targets']['ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_features(data, window_sizes):\n",
    "    extended_data = data.copy()\n",
    "    \n",
    "    for window in window_sizes:\n",
    "        for col in data.columns:\n",
    "            # Rolling mean\n",
    "            extended_data[f'{col}_rolling_mean_{window}'] = data[col].rolling(window=window, min_periods=1).mean()\n",
    "            \n",
    "            # Rolling standard deviation\n",
    "            extended_data[f'{col}_rolling_std_{window}'] = data[col].rolling(window=window, min_periods=1).std()\n",
    "            \n",
    "            # Rolling maximum\n",
    "            extended_data[f'{col}_rolling_max_{window}'] = data[col].rolling(window=window, min_periods=1).max()\n",
    "    \n",
    "    return extended_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = [1, 2, 3, 4]\n",
    "train_features = add_rolling_features(final_train_feat, window_size)\n",
    "val_features = add_rolling_features(sample_val_features, window_size)\n",
    "notime_train_features = add_time_columns(add_rolling_features(notime_final_train_feat, window_size))\n",
    "notime_val_features = add_time_columns(add_rolling_features(notime_sample_val_features, window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:25.05541\ttrain-custom_weighted_error:0.00000\teval-mae:24.61184\teval-custom_weighted_error:0.00000\n",
      "[1]\ttrain-mae:17.53921\ttrain-custom_weighted_error:0.00000\teval-mae:17.22908\teval-custom_weighted_error:0.00000\n",
      "[2]\ttrain-mae:12.27779\ttrain-custom_weighted_error:0.00000\teval-mae:12.05729\teval-custom_weighted_error:0.00000\n",
      "[3]\ttrain-mae:8.59475\ttrain-custom_weighted_error:0.00000\teval-mae:8.44115\teval-custom_weighted_error:0.00000\n",
      "[4]\ttrain-mae:6.01657\ttrain-custom_weighted_error:0.00000\teval-mae:5.90920\teval-custom_weighted_error:0.00000\n",
      "[5]\ttrain-mae:4.21179\ttrain-custom_weighted_error:0.00000\teval-mae:4.13483\teval-custom_weighted_error:0.00000\n",
      "[6]\ttrain-mae:2.94841\ttrain-custom_weighted_error:0.00000\teval-mae:2.89858\teval-custom_weighted_error:0.00000\n",
      "[7]\ttrain-mae:2.06404\ttrain-custom_weighted_error:0.00000\teval-mae:2.02740\teval-custom_weighted_error:0.00000\n",
      "[8]\ttrain-mae:1.44496\ttrain-custom_weighted_error:0.00036\teval-mae:1.42036\teval-custom_weighted_error:0.01243\n",
      "[9]\ttrain-mae:1.01159\ttrain-custom_weighted_error:0.01517\teval-mae:0.99604\teval-custom_weighted_error:0.11330\n",
      "[10]\ttrain-mae:0.70820\ttrain-custom_weighted_error:0.36823\teval-mae:0.69924\teval-custom_weighted_error:0.46015\n",
      "[11]\ttrain-mae:0.49585\ttrain-custom_weighted_error:11.29406\teval-mae:0.49255\teval-custom_weighted_error:12.38578\n",
      "[12]\ttrain-mae:0.34725\ttrain-custom_weighted_error:24.82365\teval-mae:0.34934\teval-custom_weighted_error:24.40132\n",
      "[13]\ttrain-mae:0.24331\ttrain-custom_weighted_error:25.23373\teval-mae:0.24828\teval-custom_weighted_error:25.29057\n",
      "[14]\ttrain-mae:0.17076\ttrain-custom_weighted_error:26.06906\teval-mae:0.17800\teval-custom_weighted_error:27.13447\n",
      "[15]\ttrain-mae:0.12016\ttrain-custom_weighted_error:35.29426\teval-mae:0.13081\teval-custom_weighted_error:34.42603\n",
      "[16]\ttrain-mae:0.08497\ttrain-custom_weighted_error:51.61438\teval-mae:0.09695\teval-custom_weighted_error:49.06178\n",
      "[17]\ttrain-mae:0.06064\ttrain-custom_weighted_error:66.96996\teval-mae:0.07366\teval-custom_weighted_error:62.36020\n",
      "[18]\ttrain-mae:0.04402\ttrain-custom_weighted_error:93.79742\teval-mae:0.05832\teval-custom_weighted_error:80.54561\n",
      "[19]\ttrain-mae:0.03290\ttrain-custom_weighted_error:95.26231\teval-mae:0.04826\teval-custom_weighted_error:84.64971\n",
      "[20]\ttrain-mae:0.02535\ttrain-custom_weighted_error:96.04593\teval-mae:0.04305\teval-custom_weighted_error:85.25387\n",
      "[21]\ttrain-mae:0.02045\ttrain-custom_weighted_error:96.42238\teval-mae:0.03979\teval-custom_weighted_error:87.92159\n",
      "[22]\ttrain-mae:0.01700\ttrain-custom_weighted_error:96.63894\teval-mae:0.03718\teval-custom_weighted_error:87.82108\n",
      "[23]\ttrain-mae:0.01467\ttrain-custom_weighted_error:96.70327\teval-mae:0.03530\teval-custom_weighted_error:88.38979\n",
      "[24]\ttrain-mae:0.01279\ttrain-custom_weighted_error:96.92384\teval-mae:0.03406\teval-custom_weighted_error:88.48262\n",
      "[25]\ttrain-mae:0.01158\ttrain-custom_weighted_error:97.05395\teval-mae:0.03311\teval-custom_weighted_error:88.43694\n",
      "[26]\ttrain-mae:0.01075\ttrain-custom_weighted_error:97.12395\teval-mae:0.03252\teval-custom_weighted_error:88.44534\n",
      "[27]\ttrain-mae:0.01019\ttrain-custom_weighted_error:97.19887\teval-mae:0.03210\teval-custom_weighted_error:88.81778\n",
      "[28]\ttrain-mae:0.00957\ttrain-custom_weighted_error:97.29024\teval-mae:0.03151\teval-custom_weighted_error:88.85981\n",
      "[29]\ttrain-mae:0.00934\ttrain-custom_weighted_error:97.29317\teval-mae:0.03132\teval-custom_weighted_error:88.86895\n",
      "[30]\ttrain-mae:0.00899\ttrain-custom_weighted_error:97.40355\teval-mae:0.03115\teval-custom_weighted_error:88.89709\n",
      "[31]\ttrain-mae:0.00879\ttrain-custom_weighted_error:97.51849\teval-mae:0.03103\teval-custom_weighted_error:88.88722\n",
      "[32]\ttrain-mae:0.00865\ttrain-custom_weighted_error:97.54993\teval-mae:0.03096\teval-custom_weighted_error:88.87078\n",
      "[33]\ttrain-mae:0.00855\ttrain-custom_weighted_error:97.55559\teval-mae:0.03088\teval-custom_weighted_error:88.86712\n",
      "[34]\ttrain-mae:0.00848\ttrain-custom_weighted_error:97.58319\teval-mae:0.03082\teval-custom_weighted_error:88.87991\n",
      "[35]\ttrain-mae:0.00826\ttrain-custom_weighted_error:97.65884\teval-mae:0.03130\teval-custom_weighted_error:88.82984\n",
      "[36]\ttrain-mae:0.00819\ttrain-custom_weighted_error:97.69813\teval-mae:0.03125\teval-custom_weighted_error:88.84227\n",
      "[37]\ttrain-mae:0.00814\ttrain-custom_weighted_error:97.73450\teval-mae:0.03130\teval-custom_weighted_error:88.71106\n",
      "[38]\ttrain-mae:0.00810\ttrain-custom_weighted_error:97.76904\teval-mae:0.03123\teval-custom_weighted_error:88.76807\n",
      "[39]\ttrain-mae:0.00803\ttrain-custom_weighted_error:97.85986\teval-mae:0.03123\teval-custom_weighted_error:88.76881\n",
      "[40]\ttrain-mae:0.00799\ttrain-custom_weighted_error:97.89623\teval-mae:0.03184\teval-custom_weighted_error:88.12188\n",
      "[41]\ttrain-mae:0.00793\ttrain-custom_weighted_error:97.92455\teval-mae:0.03183\teval-custom_weighted_error:88.12152\n",
      "[42]\ttrain-mae:0.00784\ttrain-custom_weighted_error:98.00277\teval-mae:0.03183\teval-custom_weighted_error:88.11311\n",
      "[43]\ttrain-mae:0.00781\ttrain-custom_weighted_error:98.01264\teval-mae:0.03184\teval-custom_weighted_error:88.11348\n",
      "[44]\ttrain-mae:0.00779\ttrain-custom_weighted_error:98.00387\teval-mae:0.03183\teval-custom_weighted_error:88.11128\n",
      "[45]\ttrain-mae:0.00751\ttrain-custom_weighted_error:98.15006\teval-mae:0.03185\teval-custom_weighted_error:88.11457\n",
      "[46]\ttrain-mae:0.00749\ttrain-custom_weighted_error:98.17875\teval-mae:0.03169\teval-custom_weighted_error:88.16136\n",
      "[47]\ttrain-mae:0.00743\ttrain-custom_weighted_error:98.21567\teval-mae:0.03167\teval-custom_weighted_error:88.18585\n",
      "[48]\ttrain-mae:0.00740\ttrain-custom_weighted_error:98.23139\teval-mae:0.03164\teval-custom_weighted_error:88.19498\n",
      "[49]\ttrain-mae:0.00736\ttrain-custom_weighted_error:98.24637\teval-mae:0.03163\teval-custom_weighted_error:88.19900\n",
      "[50]\ttrain-mae:0.00729\ttrain-custom_weighted_error:98.29699\teval-mae:0.03177\teval-custom_weighted_error:87.81158\n",
      "[51]\ttrain-mae:0.00724\ttrain-custom_weighted_error:98.29864\teval-mae:0.03176\teval-custom_weighted_error:87.80756\n",
      "[52]\ttrain-mae:0.00720\ttrain-custom_weighted_error:98.31581\teval-mae:0.03175\teval-custom_weighted_error:87.81597\n",
      "[53]\ttrain-mae:0.00709\ttrain-custom_weighted_error:98.36168\teval-mae:0.03190\teval-custom_weighted_error:87.27175\n",
      "[54]\ttrain-mae:0.00699\ttrain-custom_weighted_error:98.43496\teval-mae:0.03188\teval-custom_weighted_error:87.26956\n",
      "[55]\ttrain-mae:0.00693\ttrain-custom_weighted_error:98.45105\teval-mae:0.03196\teval-custom_weighted_error:87.25238\n",
      "[56]\ttrain-mae:0.00688\ttrain-custom_weighted_error:98.46493\teval-mae:0.03193\teval-custom_weighted_error:87.27979\n",
      "[57]\ttrain-mae:0.00684\ttrain-custom_weighted_error:98.48997\teval-mae:0.03194\teval-custom_weighted_error:87.26371\n",
      "[58]\ttrain-mae:0.00680\ttrain-custom_weighted_error:98.51428\teval-mae:0.03194\teval-custom_weighted_error:87.26298\n",
      "[59]\ttrain-mae:0.00674\ttrain-custom_weighted_error:98.53054\teval-mae:0.03227\teval-custom_weighted_error:87.23520\n",
      "[60]\ttrain-mae:0.00672\ttrain-custom_weighted_error:98.54479\teval-mae:0.03221\teval-custom_weighted_error:87.24726\n",
      "[61]\ttrain-mae:0.00670\ttrain-custom_weighted_error:98.54991\teval-mae:0.03221\teval-custom_weighted_error:87.24726\n",
      "[62]\ttrain-mae:0.00665\ttrain-custom_weighted_error:98.56106\teval-mae:0.03227\teval-custom_weighted_error:87.23447\n",
      "[63]\ttrain-mae:0.00664\ttrain-custom_weighted_error:98.56672\teval-mae:0.03227\teval-custom_weighted_error:87.23484\n",
      "[64]\ttrain-mae:0.00662\ttrain-custom_weighted_error:98.56526\teval-mae:0.03228\teval-custom_weighted_error:87.22131\n",
      "[65]\ttrain-mae:0.00659\ttrain-custom_weighted_error:98.58043\teval-mae:0.03231\teval-custom_weighted_error:87.20340\n",
      "[66]\ttrain-mae:0.00629\ttrain-custom_weighted_error:98.64512\teval-mae:0.03219\teval-custom_weighted_error:87.17636\n",
      "[67]\ttrain-mae:0.00624\ttrain-custom_weighted_error:98.69136\teval-mae:0.03215\teval-custom_weighted_error:87.19829\n",
      "[68]\ttrain-mae:0.00621\ttrain-custom_weighted_error:98.69812\teval-mae:0.03216\teval-custom_weighted_error:87.19938\n",
      "[69]\ttrain-mae:0.00619\ttrain-custom_weighted_error:98.71676\teval-mae:0.03215\teval-custom_weighted_error:87.20377\n",
      "[70]\ttrain-mae:0.00612\ttrain-custom_weighted_error:98.72060\teval-mae:0.03215\teval-custom_weighted_error:87.20158\n",
      "[71]\ttrain-mae:0.00601\ttrain-custom_weighted_error:98.74198\teval-mae:0.03212\teval-custom_weighted_error:87.20194\n",
      "[72]\ttrain-mae:0.00600\ttrain-custom_weighted_error:98.74581\teval-mae:0.03212\teval-custom_weighted_error:87.20267\n",
      "[73]\ttrain-mae:0.00599\ttrain-custom_weighted_error:98.75477\teval-mae:0.03209\teval-custom_weighted_error:87.19902\n",
      "[74]\ttrain-mae:0.00598\ttrain-custom_weighted_error:98.76135\teval-mae:0.03209\teval-custom_weighted_error:87.19573\n",
      "[75]\ttrain-mae:0.00592\ttrain-custom_weighted_error:98.77560\teval-mae:0.03202\teval-custom_weighted_error:87.19646\n",
      "[76]\ttrain-mae:0.00588\ttrain-custom_weighted_error:98.80886\teval-mae:0.03201\teval-custom_weighted_error:87.20925\n",
      "[77]\ttrain-mae:0.00583\ttrain-custom_weighted_error:98.83171\teval-mae:0.03194\teval-custom_weighted_error:87.20633\n",
      "[78]\ttrain-mae:0.00582\ttrain-custom_weighted_error:98.83682\teval-mae:0.03193\teval-custom_weighted_error:87.20596\n",
      "[79]\ttrain-mae:0.00579\ttrain-custom_weighted_error:98.85053\teval-mae:0.03196\teval-custom_weighted_error:87.20486\n",
      "[80]\ttrain-mae:0.00578\ttrain-custom_weighted_error:98.85418\teval-mae:0.03201\teval-custom_weighted_error:87.20633\n",
      "[81]\ttrain-mae:0.00574\ttrain-custom_weighted_error:98.87118\teval-mae:0.03200\teval-custom_weighted_error:87.20669\n",
      "[82]\ttrain-mae:0.00570\ttrain-custom_weighted_error:98.89658\teval-mae:0.03196\teval-custom_weighted_error:87.20048\n",
      "[83]\ttrain-mae:0.00567\ttrain-custom_weighted_error:98.92015\teval-mae:0.03196\teval-custom_weighted_error:87.19427\n",
      "[84]\ttrain-mae:0.00563\ttrain-custom_weighted_error:98.94812\teval-mae:0.03207\teval-custom_weighted_error:87.19500\n",
      "[85]\ttrain-mae:0.00562\ttrain-custom_weighted_error:98.95232\teval-mae:0.03207\teval-custom_weighted_error:87.19463\n",
      "[86]\ttrain-mae:0.00554\ttrain-custom_weighted_error:98.97370\teval-mae:0.03193\teval-custom_weighted_error:87.19865\n",
      "[87]\ttrain-mae:0.00553\ttrain-custom_weighted_error:98.97772\teval-mae:0.03193\teval-custom_weighted_error:87.20560\n",
      "[88]\ttrain-mae:0.00551\ttrain-custom_weighted_error:98.99234\teval-mae:0.03190\teval-custom_weighted_error:87.21108\n",
      "[89]\ttrain-mae:0.00547\ttrain-custom_weighted_error:99.01336\teval-mae:0.03191\teval-custom_weighted_error:87.20267\n",
      "[90]\ttrain-mae:0.00546\ttrain-custom_weighted_error:99.01683\teval-mae:0.03191\teval-custom_weighted_error:87.20231\n",
      "[91]\ttrain-mae:0.00545\ttrain-custom_weighted_error:99.02121\teval-mae:0.03191\teval-custom_weighted_error:87.21693\n",
      "[92]\ttrain-mae:0.00536\ttrain-custom_weighted_error:99.02980\teval-mae:0.03174\teval-custom_weighted_error:87.18696\n",
      "[93]\ttrain-mae:0.00534\ttrain-custom_weighted_error:99.04077\teval-mae:0.03174\teval-custom_weighted_error:87.18915\n",
      "[94]\ttrain-mae:0.00527\ttrain-custom_weighted_error:99.04570\teval-mae:0.03171\teval-custom_weighted_error:87.19609\n",
      "[95]\ttrain-mae:0.00522\ttrain-custom_weighted_error:99.06763\teval-mae:0.03167\teval-custom_weighted_error:87.20413\n",
      "[96]\ttrain-mae:0.00515\ttrain-custom_weighted_error:99.09486\teval-mae:0.03171\teval-custom_weighted_error:87.17234\n",
      "[97]\ttrain-mae:0.00514\ttrain-custom_weighted_error:99.09705\teval-mae:0.03169\teval-custom_weighted_error:87.17380\n",
      "[98]\ttrain-mae:0.00512\ttrain-custom_weighted_error:99.10491\teval-mae:0.03168\teval-custom_weighted_error:87.17965\n",
      "[99]\ttrain-mae:0.00511\ttrain-custom_weighted_error:99.10747\teval-mae:0.03168\teval-custom_weighted_error:87.18367\n",
      "[100]\ttrain-mae:0.00509\ttrain-custom_weighted_error:99.10857\teval-mae:0.03168\teval-custom_weighted_error:87.18549\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#     'objective': 'reg:squarederror',\n",
    "#     'eta': 0.075,\n",
    "#     'max_depth': 6,\n",
    "#     'min_child_weight': 1,\n",
    "#     'subsample': 1.0,\n",
    "#     'colsample_bytree': 1.0,\n",
    "#     'eval_metric': 'mae',\n",
    "#     'seed': 5\n",
    "# }\n",
    "params = {'eval_metric': 'mae'}\n",
    "\n",
    "# Convert data into DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(train_features, label=final_train_targets)\n",
    "dvalid = xgb.DMatrix(val_features, label=sample_val_targets)\n",
    "# dtrain = xgb.DMatrix(notime_train_features, label=final_train_targets)\n",
    "# dvalid = xgb.DMatrix(notime_val_features, label=sample_val_targets)\n",
    "\n",
    "# Training the model\n",
    "num_round = 1000\n",
    "early_stopping_rounds = 100\n",
    "max_time_for_learner = 360  # in seconds\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_boost_round=num_round, evals=watchlist,\n",
    "                  early_stopping_rounds=early_stopping_rounds,\n",
    "                  feval=custom_weighted_error_xgb,\n",
    "                  maximize=False, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.81048522682417\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(xgb.DMatrix(val_features))\n",
    "print(custom_weighted_error(sample_val_targets, preds.round(2))/len(preds) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10# Adjust the window size as needed\n",
    "smoothed_preds = pd.Series(preds.round(2)).rolling(window=window_size, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.60142395579012\n"
     ]
    }
   ],
   "source": [
    "print(custom_weighted_error(sample_val_targets.to_numpy(), smoothed_preds) /len(preds) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_errors_array = np.abs(smoothed_preds - sample_val_targets.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.84332100407889"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_points(abs_errors_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cc809489d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.plot(sample_val_targets.to_numpy().flatten(), label='true')\n",
    "# plt.plot(preds.round(2), label='preds')\n",
    "plt.plot(smoothed_preds, label='smooth')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f9eec38eb0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.plot(np.abs(sample_val_targets_1.to_numpy().flatten() - preds), label='normal')\n",
    "plt.plot(np.abs(sample_val_targets_1.to_numpy().flatten() - smoothed_preds), label='smooth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
