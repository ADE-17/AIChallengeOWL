{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r'C:\\Users\\ADE17\\Desktop\\Masters\\Projects\\AIChallenge_OWL\\SollIch-Hackathon_Daten\\Data_Participants3'\n",
    "def load_data(root_path, mode='train'):\n",
    "    data_dict = {}\n",
    "    if mode == 'train':\n",
    "        x_folder = \"Train_X\"\n",
    "        y_folder = \"Train_Y\"\n",
    "    else:\n",
    "        x_folder = \"Eval_X\"\n",
    "        y_folder = \"Eval_Y\"\n",
    "    x_files = os.listdir(os.path.join(root_path, x_folder))\n",
    "    y_files = os.listdir(os.path.join(root_path, y_folder))\n",
    "\n",
    "    for x_file, y_file in zip(x_files, y_files):\n",
    "        if x_file.endswith('.pq') and y_file.endswith('.pq'):\n",
    "            path_X = os.path.join(x_folder, x_file)\n",
    "            path_Y = os.path.join(y_folder, y_file)\n",
    "            df_X = pd.read_parquet(os.path.join(root_path, path_X))\n",
    "            df_Y = pd.read_parquet(os.path.join(root_path, path_Y))\n",
    "            # target_col_1 = df_X['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage']\n",
    "            targets = df_Y\n",
    "            # df_X = df_X.drop(['ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage'], axis=1)\n",
    "            date = x_file.split('_')[1:]  # Extracting month and day\n",
    "            date_key = '_'.join(date)[:5]  # Creating the 'MM_DD' format\n",
    "            data_dict[date_key] = {'features': df_X, 'targets': targets}\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "train_data = load_data(root_path)\n",
    "val_data = load_data(root_path, mode='val')\n",
    "def custom_weighted_error(true_values, predicted_values):\n",
    "    absolute_errors = np.abs(true_values - predicted_values)\n",
    "    \n",
    "    points = 0\n",
    "    for error in absolute_errors:\n",
    "        if error <= 0.05:\n",
    "            points += 1\n",
    "        elif 0.05 < error <= 0.1:\n",
    "            points += 0.5\n",
    "        elif 0.1 < error <= 0.5:\n",
    "            points += 0.25\n",
    "        else:\n",
    "            points += 0\n",
    "    \n",
    "    return points \n",
    "\n",
    "def custom_weighted_error_xgb(preds, dtrain):\n",
    "    true_values = dtrain.get_label()\n",
    "    \n",
    "    absolute_errors = np.abs(true_values - preds)\n",
    "    \n",
    "    points = 0\n",
    "    for error in absolute_errors:\n",
    "        if error <= 0.05:\n",
    "            points += 1\n",
    "        elif 0.05 < error <= 0.1:\n",
    "            points += 0.5\n",
    "        elif 0.1 < error <= 0.5:\n",
    "            points += 0.25\n",
    "        else:\n",
    "            points += 0\n",
    "    \n",
    "    return 'custom_weighted_error', points / len(preds) * 100\n",
    "\n",
    "def custom_error_duration(preds, dtrain):\n",
    "    true_values = dtrain.get_label()\n",
    "    \n",
    "    preds_array = preds.astype(float)\n",
    "    \n",
    "    absolute_errors = np.abs(true_values - preds_array)\n",
    "    \n",
    "    error_less_than_01 = np.sum(absolute_errors < 0.1) / len(absolute_errors)\n",
    "    \n",
    "    error_intervals = []\n",
    "    current_interval = 0\n",
    "    for error in absolute_errors:\n",
    "        if error > 0.1:\n",
    "            current_interval += 1\n",
    "        else:\n",
    "            if current_interval > 0:\n",
    "                error_intervals.append(current_interval)\n",
    "                current_interval = 0\n",
    "    \n",
    "    max_intervals_1 = len(absolute_errors) / 2\n",
    "    max_intervals_2 = len(absolute_errors) / 8\n",
    "    \n",
    "    points = 0\n",
    "    for interval in error_intervals:\n",
    "        if interval <= 1:\n",
    "            points += max(0, 0.5 - (interval / max_intervals_1))\n",
    "        elif 2 <= interval <= 10:\n",
    "            points += max(0, 0.25 - (interval / max_intervals_2))\n",
    "    \n",
    "    # Calculate the error duration metric\n",
    "    error_duration_points = (1 - error_less_than_01) * 100 + points\n",
    "    \n",
    "    return 'custom_error_duration', error_duration_points \n",
    "def add_time_columns(df):\n",
    "    df['Hour'] = df.index.hour\n",
    "    df['Minute'] = df.index.minute\n",
    "    df['Second'] = df.index.second\n",
    "    return df\n",
    "def create_time_series_windows(data, window_size):\n",
    "    windows_X = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        window = data.iloc[i:i + window_size]\n",
    "\n",
    "        windows_X.append(window.values.flatten())\n",
    "\n",
    "    return np.array(windows_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_features_1 = add_time_columns(train_data['03_14']['features'])\n",
    "sample_train_targets_1 = train_data['03_14']['targets']\n",
    "sample_train_features_2 = add_time_columns(train_data['03_15']['features'])\n",
    "sample_train_targets_2 = train_data['03_15']['targets']\n",
    "\n",
    "final_train_feat = pd.concat([sample_train_features_1, sample_train_features_2], axis=0)\n",
    "final_train_targets = pd.concat([sample_train_targets_1, sample_train_targets_2], axis=0)\n",
    "\n",
    "sample_val_features = add_time_columns(val_data['03_16']['features'])\n",
    "sample_val_targets = val_data['03_16']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADE17\\anaconda3\\anaconda2\\lib\\site-packages\\xgboost\\training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:33.32636\ttrain-custom_weighted_error:0.00000\teval-rmse:33.24421\teval-custom_weighted_error:0.00000\n",
      "[1]\ttrain-rmse:30.82710\ttrain-custom_weighted_error:0.00000\teval-rmse:30.75050\teval-custom_weighted_error:0.00000\n",
      "[2]\ttrain-rmse:28.51529\ttrain-custom_weighted_error:0.00000\teval-rmse:28.44378\teval-custom_weighted_error:0.00000\n",
      "[3]\ttrain-rmse:26.37685\ttrain-custom_weighted_error:0.00000\teval-rmse:26.31114\teval-custom_weighted_error:0.00000\n",
      "[4]\ttrain-rmse:24.39879\ttrain-custom_weighted_error:0.00000\teval-rmse:24.33754\teval-custom_weighted_error:0.00000\n",
      "[5]\ttrain-rmse:22.56907\ttrain-custom_weighted_error:0.00000\teval-rmse:22.51123\teval-custom_weighted_error:0.00000\n",
      "[6]\ttrain-rmse:20.87659\ttrain-custom_weighted_error:0.00000\teval-rmse:20.82343\teval-custom_weighted_error:0.00000\n",
      "[7]\ttrain-rmse:19.31101\ttrain-custom_weighted_error:0.00000\teval-rmse:19.26103\teval-custom_weighted_error:0.00000\n",
      "[8]\ttrain-rmse:17.86286\ttrain-custom_weighted_error:0.00000\teval-rmse:17.81667\teval-custom_weighted_error:0.00000\n",
      "[9]\ttrain-rmse:16.52330\ttrain-custom_weighted_error:0.00000\teval-rmse:16.47973\teval-custom_weighted_error:0.00000\n",
      "[10]\ttrain-rmse:15.28421\ttrain-custom_weighted_error:0.00000\teval-rmse:15.24381\teval-custom_weighted_error:0.00000\n",
      "[11]\ttrain-rmse:14.13804\ttrain-custom_weighted_error:0.00000\teval-rmse:14.10061\teval-custom_weighted_error:0.00000\n",
      "[12]\ttrain-rmse:13.07783\ttrain-custom_weighted_error:0.00000\teval-rmse:13.04313\teval-custom_weighted_error:0.00000\n",
      "[13]\ttrain-rmse:12.09713\ttrain-custom_weighted_error:0.00000\teval-rmse:12.06451\teval-custom_weighted_error:0.00000\n",
      "[14]\ttrain-rmse:11.18998\ttrain-custom_weighted_error:0.00000\teval-rmse:11.15929\teval-custom_weighted_error:0.00000\n",
      "[15]\ttrain-rmse:10.35086\ttrain-custom_weighted_error:0.00000\teval-rmse:10.32167\teval-custom_weighted_error:0.00000\n",
      "[16]\ttrain-rmse:9.57467\ttrain-custom_weighted_error:0.00000\teval-rmse:9.54713\teval-custom_weighted_error:0.00000\n",
      "[17]\ttrain-rmse:8.85670\ttrain-custom_weighted_error:0.00000\teval-rmse:8.83097\teval-custom_weighted_error:0.00000\n",
      "[18]\ttrain-rmse:8.19256\ttrain-custom_weighted_error:0.00000\teval-rmse:8.16769\teval-custom_weighted_error:0.00000\n",
      "[19]\ttrain-rmse:7.57823\ttrain-custom_weighted_error:0.00000\teval-rmse:7.55465\teval-custom_weighted_error:0.00000\n",
      "[20]\ttrain-rmse:7.00998\ttrain-custom_weighted_error:0.00000\teval-rmse:6.98761\teval-custom_weighted_error:0.00000\n",
      "[21]\ttrain-rmse:6.48433\ttrain-custom_weighted_error:0.00000\teval-rmse:6.46303\teval-custom_weighted_error:0.00000\n",
      "[22]\ttrain-rmse:5.99811\ttrain-custom_weighted_error:0.00000\teval-rmse:5.97792\teval-custom_weighted_error:0.00000\n",
      "[23]\ttrain-rmse:5.54835\ttrain-custom_weighted_error:0.00000\teval-rmse:5.52913\teval-custom_weighted_error:0.00000\n",
      "[24]\ttrain-rmse:5.13233\ttrain-custom_weighted_error:0.00000\teval-rmse:5.11397\teval-custom_weighted_error:0.00000\n",
      "[25]\ttrain-rmse:4.74750\ttrain-custom_weighted_error:0.00000\teval-rmse:4.72990\teval-custom_weighted_error:0.00000\n",
      "[26]\ttrain-rmse:4.39154\ttrain-custom_weighted_error:0.00000\teval-rmse:4.37466\teval-custom_weighted_error:0.00000\n",
      "[27]\ttrain-rmse:4.06227\ttrain-custom_weighted_error:0.00000\teval-rmse:4.04610\teval-custom_weighted_error:0.00000\n",
      "[28]\ttrain-rmse:3.75770\ttrain-custom_weighted_error:0.00000\teval-rmse:3.74226\teval-custom_weighted_error:0.00000\n",
      "[29]\ttrain-rmse:3.47597\ttrain-custom_weighted_error:0.00000\teval-rmse:3.46119\teval-custom_weighted_error:0.00000\n",
      "[30]\ttrain-rmse:3.21536\ttrain-custom_weighted_error:0.00000\teval-rmse:3.20122\teval-custom_weighted_error:0.00000\n",
      "[31]\ttrain-rmse:2.97430\ttrain-custom_weighted_error:0.00000\teval-rmse:2.96076\teval-custom_weighted_error:0.00000\n",
      "[32]\ttrain-rmse:2.75133\ttrain-custom_weighted_error:0.00000\teval-rmse:2.73837\teval-custom_weighted_error:0.00000\n",
      "[33]\ttrain-rmse:2.54508\ttrain-custom_weighted_error:0.00000\teval-rmse:2.53259\teval-custom_weighted_error:0.00000\n",
      "[34]\ttrain-rmse:2.35430\ttrain-custom_weighted_error:0.00000\teval-rmse:2.34230\teval-custom_weighted_error:0.00000\n",
      "[35]\ttrain-rmse:2.17782\ttrain-custom_weighted_error:0.00000\teval-rmse:2.16645\teval-custom_weighted_error:0.00000\n",
      "[36]\ttrain-rmse:2.01457\ttrain-custom_weighted_error:0.00000\teval-rmse:2.00369\teval-custom_weighted_error:0.00000\n",
      "[37]\ttrain-rmse:1.86358\ttrain-custom_weighted_error:0.00000\teval-rmse:1.85314\teval-custom_weighted_error:0.00000\n",
      "[38]\ttrain-rmse:1.72392\ttrain-custom_weighted_error:0.00000\teval-rmse:1.71389\teval-custom_weighted_error:0.00000\n",
      "[39]\ttrain-rmse:1.59472\ttrain-custom_weighted_error:0.00000\teval-rmse:1.58507\teval-custom_weighted_error:0.00000\n",
      "[40]\ttrain-rmse:1.47522\ttrain-custom_weighted_error:0.00000\teval-rmse:1.46604\teval-custom_weighted_error:0.00000\n",
      "[41]\ttrain-rmse:1.36467\ttrain-custom_weighted_error:0.00000\teval-rmse:1.35590\teval-custom_weighted_error:0.00000\n",
      "[42]\ttrain-rmse:1.26243\ttrain-custom_weighted_error:0.00091\teval-rmse:1.25394\teval-custom_weighted_error:0.00110\n",
      "[43]\ttrain-rmse:1.16785\ttrain-custom_weighted_error:0.00183\teval-rmse:1.15970\teval-custom_weighted_error:0.00365\n",
      "[44]\ttrain-rmse:1.08037\ttrain-custom_weighted_error:0.00329\teval-rmse:1.07256\teval-custom_weighted_error:0.00877\n",
      "[45]\ttrain-rmse:0.99946\ttrain-custom_weighted_error:0.00512\teval-rmse:0.99206\teval-custom_weighted_error:0.00950\n",
      "[46]\ttrain-rmse:0.92462\ttrain-custom_weighted_error:0.00694\teval-rmse:0.91772\teval-custom_weighted_error:0.04642\n",
      "[47]\ttrain-rmse:0.85539\ttrain-custom_weighted_error:0.03216\teval-rmse:0.84867\teval-custom_weighted_error:0.06323\n",
      "[48]\ttrain-rmse:0.79136\ttrain-custom_weighted_error:0.05519\teval-rmse:0.78480\teval-custom_weighted_error:0.12025\n",
      "[49]\ttrain-rmse:0.73213\ttrain-custom_weighted_error:0.34758\teval-rmse:0.72585\teval-custom_weighted_error:0.49488\n",
      "[50]\ttrain-rmse:0.67736\ttrain-custom_weighted_error:0.65496\teval-rmse:0.67145\teval-custom_weighted_error:0.72514\n",
      "[51]\ttrain-rmse:0.62670\ttrain-custom_weighted_error:5.72232\teval-rmse:0.62117\teval-custom_weighted_error:6.91547\n",
      "[52]\ttrain-rmse:0.57984\ttrain-custom_weighted_error:9.72829\teval-rmse:0.57445\teval-custom_weighted_error:11.88287\n",
      "[53]\ttrain-rmse:0.53650\ttrain-custom_weighted_error:10.84560\teval-rmse:0.53146\teval-custom_weighted_error:12.01700\n",
      "[54]\ttrain-rmse:0.49643\ttrain-custom_weighted_error:11.84449\teval-rmse:0.49154\teval-custom_weighted_error:12.32219\n",
      "[55]\ttrain-rmse:0.45937\ttrain-custom_weighted_error:12.18385\teval-rmse:0.45474\teval-custom_weighted_error:12.58352\n",
      "[56]\ttrain-rmse:0.42509\ttrain-custom_weighted_error:24.20432\teval-rmse:0.42075\teval-custom_weighted_error:24.23429\n",
      "[57]\ttrain-rmse:0.39340\ttrain-custom_weighted_error:24.61477\teval-rmse:0.38941\teval-custom_weighted_error:24.42252\n",
      "[58]\ttrain-rmse:0.36408\ttrain-custom_weighted_error:24.77413\teval-rmse:0.36046\teval-custom_weighted_error:24.59394\n",
      "[59]\ttrain-rmse:0.33698\ttrain-custom_weighted_error:24.88871\teval-rmse:0.33367\teval-custom_weighted_error:24.81652\n",
      "[60]\ttrain-rmse:0.31192\ttrain-custom_weighted_error:24.97551\teval-rmse:0.30889\teval-custom_weighted_error:25.01389\n",
      "[61]\ttrain-rmse:0.28877\ttrain-custom_weighted_error:25.02047\teval-rmse:0.28600\teval-custom_weighted_error:25.17580\n",
      "[62]\ttrain-rmse:0.26736\ttrain-custom_weighted_error:25.06853\teval-rmse:0.26497\teval-custom_weighted_error:25.36659\n",
      "[63]\ttrain-rmse:0.24757\ttrain-custom_weighted_error:25.11696\teval-rmse:0.24548\teval-custom_weighted_error:25.69297\n",
      "[64]\ttrain-rmse:0.22928\ttrain-custom_weighted_error:25.33333\teval-rmse:0.22745\teval-custom_weighted_error:25.86768\n",
      "[65]\ttrain-rmse:0.21238\ttrain-custom_weighted_error:25.53910\teval-rmse:0.21087\teval-custom_weighted_error:26.06358\n",
      "[66]\ttrain-rmse:0.19676\ttrain-custom_weighted_error:25.70558\teval-rmse:0.19563\teval-custom_weighted_error:26.56504\n",
      "[67]\ttrain-rmse:0.18234\ttrain-custom_weighted_error:25.95101\teval-rmse:0.18155\teval-custom_weighted_error:26.91920\n",
      "[68]\ttrain-rmse:0.16904\ttrain-custom_weighted_error:26.81247\teval-rmse:0.16858\teval-custom_weighted_error:27.67869\n",
      "[69]\ttrain-rmse:0.15674\ttrain-custom_weighted_error:28.17466\teval-rmse:0.15680\teval-custom_weighted_error:28.53942\n",
      "[70]\ttrain-rmse:0.14539\ttrain-custom_weighted_error:29.64595\teval-rmse:0.14585\teval-custom_weighted_error:30.39320\n",
      "[71]\ttrain-rmse:0.13491\ttrain-custom_weighted_error:31.62180\teval-rmse:0.13578\teval-custom_weighted_error:32.71261\n",
      "[72]\ttrain-rmse:0.12527\ttrain-custom_weighted_error:34.13400\teval-rmse:0.12656\teval-custom_weighted_error:35.85839\n",
      "[73]\ttrain-rmse:0.11636\ttrain-custom_weighted_error:36.08281\teval-rmse:0.11814\teval-custom_weighted_error:37.76699\n",
      "[74]\ttrain-rmse:0.10818\ttrain-custom_weighted_error:37.44627\teval-rmse:0.11043\teval-custom_weighted_error:39.42048\n",
      "[75]\ttrain-rmse:0.10062\ttrain-custom_weighted_error:38.97001\teval-rmse:0.10339\teval-custom_weighted_error:40.60138\n",
      "[76]\ttrain-rmse:0.09368\ttrain-custom_weighted_error:40.96029\teval-rmse:0.09698\teval-custom_weighted_error:42.63242\n",
      "[77]\ttrain-rmse:0.08728\ttrain-custom_weighted_error:54.53959\teval-rmse:0.09126\teval-custom_weighted_error:56.35005\n",
      "[78]\ttrain-rmse:0.08140\ttrain-custom_weighted_error:56.00357\teval-rmse:0.08609\teval-custom_weighted_error:57.51817\n",
      "[79]\ttrain-rmse:0.07600\ttrain-custom_weighted_error:58.40887\teval-rmse:0.08146\teval-custom_weighted_error:60.47353\n",
      "[80]\ttrain-rmse:0.07106\ttrain-custom_weighted_error:60.98522\teval-rmse:0.07717\teval-custom_weighted_error:63.39271\n",
      "[81]\ttrain-rmse:0.06654\ttrain-custom_weighted_error:63.65989\teval-rmse:0.07331\teval-custom_weighted_error:66.24062\n",
      "[82]\ttrain-rmse:0.06243\ttrain-custom_weighted_error:65.60102\teval-rmse:0.06983\teval-custom_weighted_error:67.85720\n",
      "[83]\ttrain-rmse:0.05867\ttrain-custom_weighted_error:66.94785\teval-rmse:0.06673\teval-custom_weighted_error:69.59511\n",
      "[84]\ttrain-rmse:0.05522\ttrain-custom_weighted_error:67.83380\teval-rmse:0.06402\teval-custom_weighted_error:70.70584\n",
      "[85]\ttrain-rmse:0.05211\ttrain-custom_weighted_error:68.47159\teval-rmse:0.06163\teval-custom_weighted_error:71.47776\n",
      "[86]\ttrain-rmse:0.04926\ttrain-custom_weighted_error:92.53282\teval-rmse:0.05949\teval-custom_weighted_error:94.83048\n",
      "[87]\ttrain-rmse:0.04669\ttrain-custom_weighted_error:93.00887\teval-rmse:0.05765\teval-custom_weighted_error:95.16893\n",
      "[88]\ttrain-rmse:0.04437\ttrain-custom_weighted_error:93.29012\teval-rmse:0.05600\teval-custom_weighted_error:95.38347\n",
      "[89]\ttrain-rmse:0.04227\ttrain-custom_weighted_error:93.46684\teval-rmse:0.05456\teval-custom_weighted_error:95.49934\n",
      "[90]\ttrain-rmse:0.04037\ttrain-custom_weighted_error:93.69911\teval-rmse:0.05335\teval-custom_weighted_error:95.54283\n",
      "[91]\ttrain-rmse:0.03867\ttrain-custom_weighted_error:93.86760\teval-rmse:0.05225\teval-custom_weighted_error:95.57645\n",
      "[92]\ttrain-rmse:0.03716\ttrain-custom_weighted_error:94.08908\teval-rmse:0.05135\teval-custom_weighted_error:95.62653\n",
      "[93]\ttrain-rmse:0.03579\ttrain-custom_weighted_error:94.27183\teval-rmse:0.05049\teval-custom_weighted_error:95.70036\n",
      "[94]\ttrain-rmse:0.03456\ttrain-custom_weighted_error:94.37289\teval-rmse:0.04979\teval-custom_weighted_error:95.70949\n",
      "[95]\ttrain-rmse:0.03350\ttrain-custom_weighted_error:94.44745\teval-rmse:0.04912\teval-custom_weighted_error:95.70767\n",
      "[96]\ttrain-rmse:0.03256\ttrain-custom_weighted_error:94.58414\teval-rmse:0.04864\teval-custom_weighted_error:95.76066\n",
      "[97]\ttrain-rmse:0.03166\ttrain-custom_weighted_error:94.66729\teval-rmse:0.04823\teval-custom_weighted_error:95.79173\n",
      "[98]\ttrain-rmse:0.03087\ttrain-custom_weighted_error:94.77036\teval-rmse:0.04782\teval-custom_weighted_error:95.78844\n",
      "[99]\ttrain-rmse:0.03022\ttrain-custom_weighted_error:94.86831\teval-rmse:0.04750\teval-custom_weighted_error:95.81402\n",
      "[100]\ttrain-rmse:0.02965\ttrain-custom_weighted_error:94.94196\teval-rmse:0.04723\teval-custom_weighted_error:95.85605\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eta': 0.075,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed': 5\n",
    "}\n",
    "\n",
    "# Convert data into DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(final_train_feat, label=final_train_targets)\n",
    "dvalid = xgb.DMatrix(sample_val_features, label=sample_val_targets)\n",
    "\n",
    "# Training the model\n",
    "num_round = 1000\n",
    "early_stopping_rounds = 100\n",
    "max_time_for_learner = 360  # in seconds\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_boost_round=num_round, evals=watchlist,\n",
    "                  early_stopping_rounds=early_stopping_rounds,\n",
    "                  feval=custom_weighted_error_xgb,\n",
    "                  maximize=False, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.85605473604187"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(xgb.DMatrix(sample_val_features))\n",
    "custom_weighted_error(sample_val_targets.to_numpy().flatten(), preds) / len(preds) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_points(estimated_values):\n",
    "    thresholds = [(0, 1), (2, 10)]\n",
    "    point_values = [0.5, 0.25]\n",
    "\n",
    "    num_estimates = len(estimated_values)\n",
    "\n",
    "    values_below_threshold = sum(1 for value in estimated_values if abs(value) < 0.1)\n",
    "    percentage_below_threshold = values_below_threshold / num_estimates * 100\n",
    "\n",
    "    points_from_percentage = percentage_below_threshold\n",
    "\n",
    "    total_points_intervals = 0\n",
    "    for i, (low, high) in enumerate(thresholds):\n",
    "        count_intervals = sum(1 for value in estimated_values if abs(value) > 0.1 and low <= value <= high)\n",
    "        \n",
    "        max_possible_intervals = num_estimates / (2 ** i) if i < len(point_values) else 0\n",
    "        \n",
    "        if max_possible_intervals > 0:\n",
    "            points_for_range = 100 - (count_intervals / max_possible_intervals * 100)\n",
    "            total_points_intervals += points_for_range * point_values[i]\n",
    "\n",
    "    total_points = points_from_percentage + total_points_intervals\n",
    "\n",
    "    return total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.32901565766582"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_points(absolute_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_errors = np.abs(sample_val_targets.to_numpy().flatten() - preds)\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24206552190>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.plot(preds)\n",
    "plt.plot(sample_val_targets.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x242065e41f0>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.plot(absolute_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0022303796236327893"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(sample_val_targets.to_numpy().flatten(), preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
